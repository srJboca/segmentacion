{
"nbformat": 4,
"nbformat_minor": 5,
"metadata": {
"colab": {
"provenance": [],
"include_colab_link": true
},
"kernelspec": {
"name": "python3",
"display_name": "Python 3"
},
"language_info": {
"name": "python"
}
},
"cells": [
{
"cell_type": "markdown",
"metadata": {
"id": "view-in-github",
"colab_type": "text"
},
"source": [
"<a href="https://colab.research.google.com/github/srJboca/segmentacion/blob/main/1.%20Exploracion.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>"
]
},
{
"cell_type": "markdown",
"source": [
"# Tutorial: Exploring Customer and Gas Billing Data\n",
"\n",
"## Introduction\n",
"\n",
"Welcome to this data exploration tutorial. We will work with a dataset that simulates the information of a gas distribution company. The goal is to clean, combine, and explore this data to better understand customers, their consumption, and payment behaviors. This process is essential before performing more advanced tasks such as customer segmentation, predictive consumption modeling, or delinquency analysis.\n",
"\n",
"The data is divided into four files:\n",
"1.  customers.parquet: Information about customers (contracts, demographic data).\n",
"2.  invoices.parquet: Details of the issued invoices (consumption, dates).\n",
"3.  gas_prices.parquet: Gas prices per m³ according to socioeconomic status, year, and month.\n",
"4.  collections.parquet: Information about the payments made for the invoices.\n",
"\n",
"## Phase 1: Environment Setup and Data Loading\n",
"\n",
"### 1.1 Importing Libraries\n",
"\n",
"First, we will import the necessary libraries.\n",
"* pandas for data manipulation and analysis.\n",
"* matplotlib.pyplot and seaborn for data visualization.\n",
"* warnings to manage any warnings that may arise."
],
"metadata": {
"id": "intro_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "import_libs_code_en"
},
"outputs": [],
"source": [
"import pandas as pd\n",
"import matplotlib.pyplot as plt\n",
"import seaborn as sns\n",
"import warnings\n",
"\n",
"warnings.filterwarnings('ignore')\n",
"\n",
"# Settings for visualizations\n",
"sns.set_style('whitegrid')\n",
"plt.rcParams['figure.figsize'] = (10, 6)"
]
},
{
"cell_type": "markdown",
"source": [
"### 1.2 Downloading the Data Files\n",
"\n",
"We will download the Parquet files from the GitHub repository."
],
"metadata": {
"id": "download_data_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "download_data_code_en"
},
"outputs": [],
"source": [
"!wget -N https://github.com/srJboca/segmentacion/raw/refs/heads/main/archivos/clientes.parquet -O customers.parquet\n",
"!wget -N https://github.com/srJboca/segmentacion/raw/refs/heads/main/archivos/facturas.parquet -O invoices.parquet\n",
"!wget -N https://github.com/srJboca/segmentacion/raw/refs/heads/main/archivos/precios_gas.parquet -O gas_prices.parquet\n",
"!wget -N https://github.com/srJboca/segmentacion/raw/refs/heads/main/archivos/recaudo.parquet -O collections.parquet"
]
},
{
"cell_type": "markdown",
"source": [
"### 1.3 Loading Data into Pandas DataFrames\n",
"\n",
"Now, we will load each Parquet file into a Pandas DataFrame."
],
"metadata": {
"id": "load_data_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "load_data_code_en"
},
"outputs": [],
"source": [
"df_customers = pd.read_parquet('customers.parquet')\n",
"df_invoices = pd.read_parquet('invoices.parquet')\n",
"df_collections = pd.read_parquet('collections.parquet')\n",
"df_gas_prices = pd.read_parquet('gas_prices.parquet')"
]
},
{
"cell_type": "markdown",
"source": [
"## Phase 2: Initial Data Inspection\n",
"\n",
"We will perform a basic inspection of each DataFrame to understand its structure, data types, and check for the presence of null values or initial descriptive statistics."
],
"metadata": {
"id": "initial_inspection_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 2.1 Customers DataFrame (df_customers)"
],
"metadata": {
"id": "inspect_customers_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "inspect_customers_code_en"
},
"outputs": [],
"source": [
"# Renaming columns to English for consistency\n",
"df_customers.columns = ['Contract Number', 'Name', 'Address', 'City', 'Socioeconomic Status', 'Contract Start Date', 'Last Periodic Review Date']\n",
"\n",
"print("--- df_customers Information ---")\n",
"df_customers.info()\n",
"print("\n--- First 5 rows of df_customers ---")\n",
"print(df_customers.head())\n",
"print("\n--- Null values in df_customers ---")\n",
"print(df_customers.isnull().sum())\n",
"print("\n--- Descriptive statistics of df_customers ---")\n",
"print(df_customers.describe(include='all'))\n",
"print("\n--- Unique value counts per column in df_customers ---")\n",
"for col in df_customers.columns:\n",
"    print(f"Column '{col}': {df_customers[col].nunique()} unique values")"
]
},
{
"cell_type": "markdown",
"source": [
"Observations about df_customers:\n",
"* Contains personal and contractual information of the customers.\n",
"* Columns like City and Socioeconomic Status are categorical and could be important for segmentation.\n",
"* The dates are objects, we will need to convert them to datetime type.\n",
"* Contract Number appears to be the unique identifier."
],
"metadata": {
"id": "obs_customers_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 2.2 Invoices DataFrame (df_invoices)"
],
"metadata": {
"id": "inspect_invoices_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "inspect_invoices_code_en"
},
"outputs": [],
"source": [
"# Renaming columns to English\n",
"df_invoices.columns = ['Invoice Number', 'Contract Number', 'Year', 'Month', 'Issue Date', 'Consumption (m3)', 'On-time Payment Date', 'Reading Date', 'Estimated Suspension Date']\n",
"\n",
"print("--- df_invoices Information ---")\n",
"df_invoices.info()\n",
"print("\n--- First 5 rows of df_invoices ---")\n",
"print(df_invoices.head())\n",
"print("\n--- Null values in df_invoices ---")\n",
"print(df_invoices.isnull().sum())\n",
"print("\n--- Descriptive statistics of df_invoices ---")\n",
"print(df_invoices.describe(include='all'))\n",
"print("\n--- Unique value counts per column in df_invoices ---")\n",
"for col in df_invoices.columns:\n",
"    print(f"Column '{col}': {df_invoices[col].nunique()} unique values")"
]
},
{
"cell_type": "markdown",
"source": [
"Observations about df_invoices:\n",
"* Contains details of each invoice, including consumption and relevant dates.\n",
"* Invoice Number is the identifier of the invoice and Contract Number links it to the customer.\n",
"* Consumption (m3) is a key numerical variable.\n",
"* The dates are also objects."
],
"metadata": {
"id": "obs_invoices_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 2.3 Collections DataFrame (df_collections)"
],
"metadata": {
"id": "inspect_collections_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "inspect_collections_code_en"
},
"outputs": [],
"source": [
"# Renaming columns to English\n",
"df_collections.columns = ['Invoice Number', 'Actual Payment Date']\n",
"\n",
"print("--- df_collections Information ---")\n",
"df_collections.info()\n",
"print("\n--- First 5 rows of df_collections ---")\n",
"print(df_collections.head())\n",
"print("\n--- Null values in df_collections ---")\n",
"print(df_collections.isnull().sum())\n",
"print("\n--- Descriptive statistics of df_collections ---")\n",
"print(df_collections.describe(include='all'))\n",
"print("\n--- Unique value counts per column in df_collections ---")\n",
"for col in df_collections.columns:\n",
"    print(f"Column '{col}': {df_collections[col].nunique()} unique values")"
]
},
{
"cell_type": "markdown",
"source": [
"Observations about df_collections:\n",
"* Records the date on which an invoice payment was made.\n",
"* It joins to df_invoices using Invoice Number.\n",
"* Actual Payment Date will need conversion to datetime."
],
"metadata": {
"id": "obs_collections_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 2.4 Gas Prices DataFrame (df_gas_prices)"
],
"metadata": {
"id": "inspect_prices_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "inspect_prices_code_en"
},
"outputs": [],
"source": [
"# Renaming columns to English\n",
"df_gas_prices.columns = ['Year', 'Month', 'Status', 'Price m3 (COP)']\n",
"\n",
"print("--- df_gas_prices Information ---")\n",
"df_gas_prices.info()\n",
"print("\n--- First 5 rows of df_gas_prices ---")\n",
"print(df_gas_prices.head())\n",
"print("\n--- Null values in df_gas_prices ---")\n",
"print(df_gas_prices.isnull().sum())\n",
"print("\n--- Descriptive statistics of df_gas_prices ---")\n",
"print(df_gas_prices.describe(include='all'))\n",
"print("\n--- Unique value counts per column in df_gas_prices ---")\n",
"for col in df_gas_prices.columns:\n",
"    print(f"Column '{col}': {df_gas_prices[col].nunique()} unique values")"
]
},
{
"cell_type": "markdown",
"source": [
"Observations about df_gas_prices:\n",
"* Defines the price of m³ of gas according to Year, Month, and Status.\n",
"* Price m3 (COP) is the numerical value of the price.\n",
"* Status is categorical."
],
"metadata": {
"id": "obs_prices_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"## Phase 3: Merging the Data\n",
"\n",
"To have a consolidated view, we will merge these DataFrames."
],
"metadata": {
"id": "merge_intro_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 3.1 Joining Invoices with Customer Information\n",
"\n",
"We join df_invoices with df_customers using Contract Number as the key."
],
"metadata": {
"id": "merge_invoice_customer_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "merge_invoice_customer_code_en"
},
"outputs": [],
"source": [
"df_invoice_customer = pd.merge(df_invoices, df_customers, on='Contract Number', how='left')\n",
"print("--- df_invoice_customer Information (Invoices + Customers) ---")\n",
"df_invoice_customer.info()\n",
"print("\n--- First 5 rows of df_invoice_customer ---")\n",
"print(df_invoice_customer.head())\n",
"print(f"\nShape of df_invoices: {df_invoices.shape}")\n",
"print(f"Shape of df_invoice_customer: {df_invoice_customer.shape}")"
]
},
{
"cell_type": "markdown",
"source": [
"Verification: The number of rows should be equal to that of df_invoices if each invoice has a corresponding customer (using how='left'). If it increases, it could indicate duplicates in df_customers by Contract Number, which should not happen."
],
"metadata": {
"id": "verify_merge1_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 3.2 Adding Prices to Invoices\n",
"\n",
"Now we join df_invoice_customer with df_gas_prices. The join is done using Year, Month, and the customer's socioeconomic status."
],
"metadata": {
"id": "merge_prices_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "merge_prices_code_en"
},
"outputs": [],
"source": [
"df_invoice_customer_price = pd.merge(df_invoice_customer,\n",
"                                     df_gas_prices,\n",
"                                     left_on=['Year', 'Month', 'Socioeconomic Status'],\n",
"                                     right_on=['Year', 'Month', 'Status'],\n",
"                                     how='left')\n",
"\n",
"print("--- df_invoice_customer_price Information (Invoices + Customers + Prices) ---")\n",
"df_invoice_customer_price.info()\n",
"print("\n--- First 5 rows of df_invoice_customer_price ---")\n",
"print(df_invoice_customer_price.head())\n",
"print(f"\nShape of df_invoice_customer: {df_invoice_customer.shape}")\n",
"print(f"Shape of df_invoice_customer_price: {df_invoice_customer_price.shape}")\n",
"\n",
"# Check for rows where the price could not be assigned (NaN in 'Price m3 (COP)')\n",
"print("\n--- Rows without an assigned price ---")\n",
"print(df_invoice_customer_price[df_invoice_customer_price['Price m3 (COP)'].isnull()].head())"
]
},
{
"cell_type": "markdown",
"source": [
"Verification and Potential Issues:\n",
"* Again, the number of rows should be consistent. If it increases drastically, it could indicate that the join keys ['Year', 'Month', 'Socioeconomic Status'] are not unique in df_gas_prices for a given combination, or that there are multiple invoices for the same customer in the same month with the same status being mapped (which is expected).\n",
"* The Status column from df_gas_prices is redundant after the merge and can be dropped.\n",
"* It is crucial to check if there are invoices to which a price could not be assigned. This could occur if any combination of Year, Month, Socioeconomic Status in the invoices does not exist in the price table."
],
"metadata": {
"id": "verify_merge2_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 3.3 Incorporating Payment Information (Collections)\n",
"\n",
"Finally, we join the payment information from df_collections."
],
"metadata": {
"id": "merge_collections_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "merge_collections_code_en"
},
"outputs": [],
"source": [
"df_complete = pd.merge(df_invoice_customer_price,\n",
"                       df_collections,\n",
"                       on='Invoice Number',\n",
"                       how='left') # We use a left join to keep all invoices, even if they have no payment registered\n",
"\n",
"print("--- df_complete Information (All data joined) ---")\n",
"df_complete.info()\n",
"print("\n--- First 5 rows of df_complete ---")\n",
"print(df_complete.head())\n",
"print(f"\nShape of df_invoice_customer_price: {df_invoice_customer_price.shape}")\n",
"print(f"Shape of df_complete: {df_complete.shape}")\n",
"\n",
"# Check for invoices without an actual payment date\n",
"print("\n--- Invoices without actual payment date (NaN in 'Actual Payment Date') ---")\n",
"print(df_complete[df_complete['Actual Payment Date'].isnull()][['Invoice Number', 'Issue Date', 'On-time Payment Date']].head())"
]
},
{
"cell_type": "markdown",
"source": [
"Verification:\n",
"* The number of rows should remain the same or increase if an invoice has multiple payment records (uncommon unless they are unconsolidated partial payments). A left join ensures that all invoices are kept.\n",
"* Invoices without a corresponding Actual Payment Date will have NaN in that column. This is expected for unpaid invoices or those whose payment has not yet been registered."
],
"metadata": {
"id": "verify_merge3_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 3.4 Column Selection and Handling Duplicates\n",
"\n",
"The original df_analisis DataFrame selected a subset of columns. We will replicate this and then handle potential duplicates that may have been generated in the merges, especially if the keys were not perfectly unique or if the same information was joined multiple times."
],
"metadata": {
"id": "select_cols_dups_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "select_cols_dups_code_en"
},
"outputs": [],
"source": [
"selected_columns = [\n",
"    'Invoice Number', 'Contract Number', 'Issue Date', 'Consumption (m3)',\n",
"    'On-time Payment Date', 'Reading Date', 'Estimated Suspension Date',\n",
"    'City', 'Socioeconomic Status',\n",
"    'Price m3 (COP)', 'Actual Payment Date'\n",
"]\n",
"\n",
"if 'Status' in df_complete.columns and 'Socioeconomic Status' in df_complete.columns:\n",
"    df_complete = df_complete.drop(columns=['Status'])\n",
"\n",
"df_analysis = df_complete[selected_columns].copy()\n",
"\n",
"print("--- First rows of df_analysis (before handling duplicates) ---")\n",
"print(df_analysis.head())\n",
"print(f"\nShape of df_analysis before drop_duplicates: {df_analysis.shape}")\n",
"\n",
"num_duplicates_before = df_analysis.duplicated().sum()\n",
"print(f"Number of exact duplicate rows before: {num_duplicates_before}")\n",
"\n",
"df_analysis = df_analysis.drop_duplicates()\n",
"print(f"\nShape of df_analysis after drop_duplicates: {df_analysis.shape}")\n",
"num_duplicates_after = df_analysis.duplicated().sum()\n",
"print(f"Number of exact duplicate rows after: {num_duplicates_after}")\n",
"\n",
"print("\n--- First rows of df_analysis (after handling duplicates) ---")\n",
"print(df_analysis.head())\n",
"df_analysis.info()"
]
},
{
"cell_type": "markdown",
"source": [
"Note on Duplicates:\n",
"The original notebook showed duplicate rows after the merges. The drop_duplicates() step is crucial to ensure the integrity of the analysis. It's important to investigate why duplicates were generated (e.g., non-unique merge keys? source data with duplicates?). For now, we have removed them."
],
"metadata": {
"id": "note_duplicates_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"## Phase 4: Feature Engineering\n",
"\n",
"We will create new columns from existing ones to enrich our analysis."
],
"metadata": {
"id": "feature_eng_intro_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 4.1 Date Conversion\n",
"\n",
"We convert the date columns to datetime format."
],
"metadata": {
"id": "convert_dates_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "convert_dates_code_en"
},
"outputs": [],
"source": [
"date_cols = ['Issue Date', 'On-time Payment Date', 'Reading Date', 'Actual Payment Date', 'Estimated Suspension Date']\n",
"for col in date_cols:\n",
"    df_analysis[col] = pd.to_datetime(df_analysis[col], errors='coerce')\n",
"\n",
"print("--- Data types after converting dates ---")\n",
"df_analysis.info()"
]
},
{
"cell_type": "markdown",
"source": [
"### 4.2 Calculating the Invoice Amount (Price per Consumption)"
],
"metadata": {
"id": "calc_price_consumption_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "calc_price_consumption_code_en"
},
"outputs": [],
"source": [
"df_analysis['Price per Consumption'] = df_analysis['Price m3 (COP)'] * df_analysis['Consumption (m3)']\n",
"print("\n--- df_analysis with 'Price per Consumption' ---")\n",
"print(df_analysis[['Consumption (m3)', 'Price m3 (COP)', 'Price per Consumption']].head())"
]
},
{
"cell_type": "markdown",
"source": [
"### 4.3 Calculating Time Differences\n",
"\n",
"We will calculate the days between different key events."
],
"metadata": {
"id": "calc_days_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "calc_days_code_en"
},
"outputs": [],
"source": [
"df_analysis['Days_Issue_OnTimePayment'] = (df_analysis['On-time Payment Date'] - df_analysis['Issue Date']).dt.days\n",
"df_analysis['Days_Reading_Issue'] = (df_analysis['Issue Date'] - df_analysis['Reading Date']).dt.days\n",
"df_analysis['Days_OnTimePayment_ActualPayment'] = (df_analysis['Actual Payment Date'] - df_analysis['On-time Payment Date']).dt.days\n",
"\n",
"print("\n--- df_analysis with new days features ---")\n",
"print(df_analysis[['Issue Date', 'On-time Payment Date', 'Reading Date', 'Actual Payment Date',\n",
"                   'Days_Issue_OnTimePayment', 'Days_Reading_Issue', 'Days_OnTimePayment_ActualPayment']].head())"
]
},
{
"cell_type": "markdown",
"source": [
"### 4.4 Identifying Late Payments\n",
"\n",
"We create a binary column Late Payment: 1 if the payment was made after the on-time payment date, 0 if it was paid on time or earlier. It is considered 0 if there is no actual payment date (NaT)."
],
"metadata": {
"id": "calc_late_payment_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "calc_late_payment_code_en"
},
"outputs": [],
"source": [
"df_analysis['Late Payment'] = 0\n",
"df_analysis.loc[df_analysis['Days_OnTimePayment_ActualPayment'] > 0, 'Late Payment'] = 1\n",
"df_analysis.loc[df_analysis['Days_OnTimePayment_ActualPayment'].isnull(), 'Late Payment'] = 0\n",
"\n",
"print("\n--- df_analysis with 'Late Payment' column ---")\n",
"print(df_analysis[['On-time Payment Date', 'Actual Payment Date', 'Days_OnTimePayment_ActualPayment', 'Late Payment']].head(10))\n",
"print("\nValue counts in 'Late Payment':")\n",
"print(df_analysis['Late Payment'].value_counts(dropna=False))"
]
},
{
"cell_type": "markdown",
"source": [
"## Phase 5: Detailed Exploration of the Consolidated DataFrame (df_analysis)\n",
"\n",
"Now that we have a clean and enriched DataFrame, we can explore it more deeply."
],
"metadata": {
"id": "eda_intro_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 5.1 General Summary and Null Values"
],
"metadata": {
"id": "eda_summary_nulls_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "eda_summary_nulls_code_en"
},
"outputs": [],
"source": [
"print("--- General information of df_analysis ---")\n",
"df_analysis.info()\n",
"\n",
"print("\n--- Null values in df_analysis ---")\n",
"print(df_analysis.isnull().sum())\n",
"\n",
"print("\n--- Descriptive statistics of df_analysis ---")\n",
"print(df_analysis.describe(include='all', datetime_is_numeric=True))"
]
},
{
"cell_type": "markdown",
"source": [
"Observations on null values:\n",
"* Estimated Suspension Date: May have nulls if not all invoices have this date.\n",
"* Price m3 (COP) and Price per Consumption: Nulls here would indicate problems in the merge with df_gas_prices or missing data in the price table.\n",
"* Actual Payment Date and Days_OnTimePayment_ActualPayment: Nulls are expected for unpaid invoices.\n",
"\n",
"It's important to decide how to handle these nulls. For some variables, they could be imputed, for others (like Actual Payment Date), their absence is informative."
],
"metadata": {
"id": "obs_nulls_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 5.2 Distribution of Key Numerical Variables"
],
"metadata": {
"id": "dist_numeric_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "dist_numeric_code_en"
},
"outputs": [],
"source": [
"numerical_cols_to_plot = ['Consumption (m3)', 'Price m3 (COP)', 'Price per Consumption',\n",
"                           'Days_Issue_OnTimePayment', 'Days_Reading_Issue', 'Days_OnTimePayment_ActualPayment']\n",
"\n",
"for col in numerical_cols_to_plot:\n",
"    plt.figure(figsize=(12, 5))\n",
"\n",
"    plt.subplot(1, 2, 1)\n",
"    sns.histplot(df_analysis[col].dropna(), kde=True, bins=30) # dropna() to avoid errors with NaT/NaN in histplot\n",
"    plt.title(f'Distribution of {col}')\n",
"\n",
"    plt.subplot(1, 2, 2)\n",
"    sns.boxplot(y=df_analysis[col].dropna())\n",
"    plt.title(f'Boxplot of {col}')\n",
"\n",
"    plt.tight_layout()\n",
"    plt.show()\n",
"    print(f"Statistics for {col}:\n{df_analysis[col].describe()}\n")"
]
},
{
"cell_type": "markdown",
"source": [
"Interpretation of distributions:\n",
"* Consumption (m3): Observe the shape of the distribution. Is it symmetric, skewed? Are there outliers (very high or low consumption)?\n",
"* Price m3 (COP): Does it vary much? This will depend on the socioeconomic status and the temporal evolution.\n",
"* Price per Consumption: Similar to consumption, but scaled by price.\n",
"* Days Variables:\n",
"    * Days_Issue_OnTimePayment: Timeframe to pay. Is it constant?\n",
"    * Days_Reading_Issue: Time between reading and issuance. Is it consistent?\n",
"    * Days_OnTimePayment_ActualPayment: Positive values indicate late payment. Negative, early payment. Zero, payment on the due date. The high concentration of negative or zero values in the head of the original notebook suggests timely or early payments for those cases. The boxplot can show the magnitude of the delay or advance."
],
"metadata": {
"id": "interpret_dist_numeric_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 5.3 Distribution of Key Categorical Variables"
],
"metadata": {
"id": "dist_categorical_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "dist_categorical_code_en"
},
"outputs": [],
"source": [
"categorical_cols_to_plot = ['City', 'Socioeconomic Status', 'Late Payment']\n",
"\n",
"for col in categorical_cols_to_plot:\n",
"    plt.figure(figsize=(8, 5))\n",
"    sns.countplot(data=df_analysis, x=col, order=df_analysis[col].value_counts(dropna=False).index)\n",
"    plt.title(f'Distribution of {col}')\n",
"    plt.xticks(rotation=45)\n",
"    plt.show()\n",
"    print(f"Counts for {col}:\n{df_analysis[col].value_counts(dropna=False)}\n")"
]
},
{
"cell_type": "markdown",
"source": [
"Interpretation of categorical distributions:\n",
"* City: How are the invoices/customers distributed by city?\n",
"* Socioeconomic Status: Which statuses are the most common?\n",
"* Late Payment: What proportion of invoices are paid late?"
],
"metadata": {
"id": "interpret_dist_categorical_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 5.4 Correlation Analysis (Numerical Variables)"
],
"metadata": {
"id": "correlation_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "correlation_code_en"
},
"outputs": [],
"source": [
"numerical_df = df_analysis.select_dtypes(include=['number'])\n",
"\n",
"plt.figure(figsize=(12, 8))\n",
"correlation_matrix = numerical_df.corr()\n",
"sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)\n",
"plt.title('Correlation Matrix of Numerical Variables')\n",
"plt.show()\n",
"\n",
"print("\n--- Pairs with the highest absolute correlation ---")\n",
"corr_pairs = correlation_matrix.unstack()\n",
"sorted_pairs = corr_pairs.sort_values(kind="quicksort", ascending=False)\n",
"unique_corr_pairs = sorted_pairs[(abs(sorted_pairs) < 1) & (abs(sorted_pairs) > 0.5)].drop_duplicates() # Filter > 0.5 for relevance\n",
"print(unique_corr_pairs.head(10))"
]
},
{
"cell_type": "markdown",
"source": [
"Interpretation of the Correlation Matrix:\n",
"* Look for correlation coefficients close to 1 (strong positive correlation) or -1 (strong negative correlation).\n",
"* For example, a high correlation is expected between Consumption (m3) and Price per Consumption.\n",
"* Unexpected correlations can reveal interesting insights."
],
"metadata": {
"id": "interpret_correlation_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"### 5.5 Relationships between Variables\n",
"\n",
"Let's explore some specific relationships."
],
"metadata": {
"id": "relationships_intro_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"#### 5.5.1 Average consumption by Socioeconomic Status and City"
],
"metadata": {
"id": "consumption_status_city_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "consumption_status_city_code_en"
},
"outputs": [],
"source": [
"plt.figure(figsize=(12, 6))\n",
"sns.barplot(data=df_analysis, x='Socioeconomic Status', y='Consumption (m3)', hue='City', estimator=pd.Series.mean, errorbar=None, order=sorted(df_analysis['Socioeconomic Status'].dropna().unique()))\n",
"plt.title('Average Consumption (m3) by Socioeconomic Status and City')\n",
"plt.ylabel('Average Consumption (m3)')\n",
"plt.xlabel('Socioeconomic Status')\n",
"plt.xticks(rotation=45)\n",
"plt.legend(title='City')\n",
"plt.show()\n",
"\n",
"plt.figure(figsize=(14, 7))\n",
"sns.boxplot(data=df_analysis, x='Socioeconomic Status', y='Consumption (m3)', hue='City', order=sorted(df_analysis['Socioeconomic Status'].dropna().unique()))\n",
"plt.title('Distribution of Consumption (m3) by Socioeconomic Status and City')\n",
"plt.ylabel('Consumption (m3)')\n",
"plt.xlabel('Socioeconomic Status')\n",
"plt.xticks(rotation=45)\n",
"plt.legend(title='City')\n",
"plt.show()"
]
},
{
"cell_type": "markdown",
"source": [
"#### 5.5.2 Late Payment Rate by Socioeconomic Status and City"
],
"metadata": {
"id": "late_payment_status_city_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "late_payment_status_city_code_en"
},
"outputs": [],
"source": [
"late_payment_by_status_city = df_analysis.groupby(['Socioeconomic Status', 'City'])['Late Payment'].mean().reset_index()\n",
"late_payment_by_status_city = late_payment_by_status_city.rename(columns={'Late Payment': 'Late Payment Rate'})\n",
"\n",
"plt.figure(figsize=(12, 6))\n",
"sns.barplot(data=late_payment_by_status_city, x='Socioeconomic Status', y='Late Payment Rate', hue='City', order=sorted(late_payment_by_status_city['Socioeconomic Status'].dropna().unique()))\n",
"plt.title('Late Payment Rate by Socioeconomic Status and City')\n",
"plt.ylabel('Late Payment Rate (Proportion)')\n",
"plt.xlabel('Socioeconomic Status')\n",
"plt.xticks(rotation=45)\n",
"plt.legend(title='City')\n",
"plt.show()"
]
},
{
"cell_type": "markdown",
"source": [
"### 5.6 Temporal Analysis (Example: Consumption over time)"
],
"metadata": {
"id": "temporal_analysis_markdown_en"
}
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"id": "temporal_analysis_code_en"
},
"outputs": [],
"source": [
"df_temporal = df_analysis.set_index('Issue Date').sort_index()\n",
"\n",
"monthly_consumption = df_temporal['Consumption (m3)'].resample('ME').mean()\n",
"\n",
"plt.figure(figsize=(14, 7))\n",
"monthly_consumption.plot(marker='o', linestyle='-')\n",
"plt.title('Average Monthly Gas Consumption (m3) over Time')\n",
"plt.xlabel('Issue Date (Month)')\n",
"plt.ylabel('Average Consumption (m3)')\n",
"plt.grid(True)\n",
"plt.show()\n",
"\n",
"monthly_invoices = df_temporal.resample('ME').size()\n",
"plt.figure(figsize=(14, 7))\n",
"monthly_invoices.plot(kind='bar')\n",
"plt.title('Number of Invoices Issued per Month')\n",
"plt.xlabel('Issue Date (Month)')\n",
"plt.ylabel('Number of Invoices')\n",
"plt.xticks(rotation=45)\n",
"plt.grid(axis='y')\n",
"plt.show()"
]
},
{
"cell_type": "markdown",
"source": [
"Interpretation of Temporal Analysis:\n",
"* Are there trends in consumption (increase, decrease)?\n",
"* Is seasonality observed (peaks in certain months)?\n",
"* The number of invoices can indicate customer base growth or fluctuations in billing."
],
"metadata": {
"id": "interpret_temporal_markdown_en"
}
},
{
"cell_type": "markdown",
"source": [
"## Phase 6: Exploration Conclusions and Next Steps\n",
"\n",
"In this exploratory phase, we have:\n",
"1.  Loaded and performed an initial inspection of four data sources.\n",
"2.  Combined the data into a unified DataFrame (df_analysis).\n",
"3.  Identified and handled duplicate rows that arose during the merges.\n",
"4.  Performed feature engineering, creating new variables such as Price per Consumption, time differences, and a Late Payment indicator.\n",
"5.  Explored the distributions of key numerical and categorical variables.\n",
g"6.  Analyzed correlations and relationships between variables (e.g., consumption by status, late payment by status).\n",
"7.  Conducted a brief temporal analysis of consumption."
],
"metadata": {
"id": "conclusions_markdown_en"
}
}
]
}