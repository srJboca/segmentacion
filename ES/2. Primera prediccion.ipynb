{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srJboca/segmentacion/blob/main/ES/2.%20Primera%20prediccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Predicción de Mora en Pagos de Facturas de Gas\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Este notebook es la continuación del tutorial de exploración de datos. Aquí, utilizaremos el DataFrame `df_analisis.parquet` (previamente limpiado y enriquecido) para construir un modelo de Machine Learning capaz de predecir si una factura entrará en mora (es decir, si se pagará después de la fecha de pago oportuno).\n",
        "\n",
        "**Objetivo:** Predecir la variable `Mora`.\n",
        "\n",
        "**Pasos que seguiremos:**\n",
        "1.  Carga de datos y librerías.\n",
        "2.  Revisión rápida y preparación final de los datos para el modelado.\n",
        "3.  Selección de características (features) y variable objetivo (target).\n",
        "4.  Codificación de variables categóricas.\n",
        "5.  División de datos en conjuntos de entrenamiento y prueba.\n",
        "6.  Entrenamiento de un modelo de Clasificación (Random Forest).\n",
        "7.  Evaluación del modelo (Accuracy, Reporte de Clasificación, Matriz de Confusión).\n",
        "8.  Análisis de la importancia de las características.\n",
        "9.  Discusión de resultados y próximos pasos."
      ],
      "metadata": {
        "id": "intro_prediction_markdown"
      },
      "id": "intro_prediction_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuración del Entorno y Carga de Datos"
      ],
      "metadata": {
        "id": "setup_markdown"
      },
      "id": "setup_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Importación de Librerías"
      ],
      "metadata": {
        "id": "import_libs_pred_markdown"
      },
      "id": "import_libs_pred_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libs_pred_code"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder # Aunque preferiremos un encoding manual para Estrato\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "id": "import_libs_pred_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Descarga y Carga del DataFrame Preprocesado\n",
        "\n",
        "Utilizaremos el archivo `df_analisis.parquet` que fue el resultado del notebook de exploración y preparación de datos."
      ],
      "metadata": {
        "id": "load_preprocessed_data_markdown"
      },
      "id": "load_preprocessed_data_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_preprocessed_data_code"
      },
      "outputs": [],
      "source": [
        "!wget -N https://github.com/srJboca/segmentacion/raw/refs/heads/main/archivos/df_analisis.parquet\n",
        "df_analisis_original = pd.read_parquet('df_analisis.parquet')"
      ],
      "id": "load_preprocessed_data_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Revisión Rápida y Preparación Final de Datos"
      ],
      "metadata": {
        "id": "data_review_prep_markdown"
      },
      "id": "data_review_prep_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_review_code"
      },
      "outputs": [],
      "source": [
        "print(\"--- Primeras 5 filas de df_analisis_original ---\")\n",
        "print(df_analisis_original.head())\n",
        "print(\"\\n--- Información de df_analisis_original ---\")\n",
        "df_analisis_original.info()\n",
        "print(\"\\n--- Columnas presentes ---\")\n",
        "print(df_analisis_original.columns.tolist())"
      ],
      "id": "data_review_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones:**\n",
        "* El DataFrame cargado (`df_analisis.parquet`) puede tener dos columnas relacionadas con la mora: `mora` (en minúsculas) y `Mora` (en mayúsculas). Esto es un artefacto de cómo se guardó el archivo en el notebook anterior. La columna `Mora` (con mayúscula) fue la que creamos con la lógica definida (1 si `Dias_PagoOportuno_PagoReal > 0`, 0 en caso contrario).\n",
        "* Nos aseguraremos de usar la columna `Mora` correcta y eliminaremos la redundante si existe."
      ],
      "metadata": {
        "id": "obs_mora_column_markdown"
      },
      "id": "obs_mora_column_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "handle_mora_column_code"
      },
      "outputs": [],
      "source": [
        "df_modelar = df_analisis_original.copy()\n",
        "\n",
        "# Verificar si ambas columnas 'mora' y 'Mora' existen\n",
        "if 'mora' in df_modelar.columns and 'Mora' in df_modelar.columns:\n",
        "    print(\"Ambas columnas 'mora' y 'Mora' existen. Se procederá a usar 'Mora' y eliminar 'mora'.\")\n",
        "    # Antes de eliminar, podríamos verificar si son idénticas o cuál es la correcta\n",
        "    # Asumimos que 'Mora' (mayúscula) es la calculada intencionalmente.\n",
        "    df_modelar = df_modelar.drop(columns=['mora'])\n",
        "elif 'mora' in df_modelar.columns and 'Mora' not in df_modelar.columns:\n",
        "    print(\"Solo existe la columna 'mora'. Se renombrará a 'Mora'.\")\n",
        "    df_modelar = df_modelar.rename(columns={'mora': 'Mora'})\n",
        "\n",
        "print(\"\\n--- Columnas después de manejar 'mora'/'Mora' ---\")\n",
        "print(df_modelar.columns.tolist())"
      ],
      "id": "handle_mora_column_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Selección de Características y Variable Objetivo"
      ],
      "metadata": {
        "id": "feature_selection_markdown"
      },
      "id": "feature_selection_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccionaremos las características (features) que usaremos para predecir la variable `Mora` (target).\n",
        "\n",
        "**Importante sobre Data Leakage:**\n",
        "La columna `Dias_PagoOportuno_PagoReal` se calcula usando `Fecha de Pago Real` y `Fecha de Pago Oportuno`. La variable `Mora` se define directamente a partir del signo de `Dias_PagoOportuno_PagoReal`. Por lo tanto, **NO debemos usar `Dias_PagoOportuno_PagoReal` como una característica** para predecir `Mora`, ya que esto constituiría data leakage (fuga de datos) y el modelo aprendería una relación trivial, mostrando un rendimiento artificialmente perfecto.\n",
        "\n",
        "Características candidatas iniciales del notebook original:\n",
        "`Consumo (m3)`, `Estrato`, `Precio por Consumo`, `Dias_Emision_PagoOportuno`, `Dias_Lectura_Emision`."
      ],
      "metadata": {
        "id": "data_leakage_warning_markdown"
      },
      "id": "data_leakage_warning_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_selection_code"
      },
      "outputs": [],
      "source": [
        "# Columnas para el modelo, excluyendo el identificador y la columna que causa leakage\n",
        "features_seleccionadas = [\n",
        "    'Consumo (m3)',\n",
        "    'Estrato', # Esta es la columna de estrato socioeconómico original.\n",
        "    'Precio por Consumo',\n",
        "    'Dias_Emision_PagoOportuno',\n",
        "    'Dias_Lectura_Emision'\n",
        "]\n",
        "target = 'Mora'\n",
        "\n",
        "# Asegurarse de que 'Estrato socioeconomico' se llame 'Estrato' si es necesario\n",
        "if 'Estrato socioeconomico' in df_modelar.columns and 'Estrato' not in features_seleccionadas:\n",
        "    if 'Estrato' not in df_modelar.columns: # Solo renombrar si 'Estrato' no existe\n",
        "         df_modelar = df_modelar.rename(columns={'Estrato socioeconomico': 'Estrato'})\n",
        "    elif 'Estrato' in df_modelar.columns and 'Estrato socioeconomico' in df_modelar.columns:\n",
        "         # Si ambas existen, y 'Estrato' es la de precios_gas, usar 'Estrato socioeconomico'\n",
        "         # y asegurarse que 'Estrato' en features_seleccionadas se refiere a la correcta\n",
        "         # Por simplicidad, asumimos que el df_analisis.parquet ya tiene la columna 'Estrato' correcta (la socioeconómica)\n",
        "         # Si 'Estrato' es de df_precios_gas (ya procesado en el notebook anterior), está bien.\n",
        "         # Si no, preferir 'Estrato socioeconomico' y renombrar.\n",
        "         # El df_analisis.parquet del notebook anterior tiene 'Estrato' (que era 'Estrato socioeconomico')\n",
        "         pass # Asumimos que 'Estrato' ya es la columna socioeconómica correcta.\n",
        "\n",
        "df_prediccion = df_modelar[features_seleccionadas + [target]].copy()\n",
        "\n",
        "print(\"--- DataFrame para predicción (df_prediccion) ---\")\n",
        "print(df_prediccion.head())\n",
        "print(\"\\n--- Tipos de datos en df_prediccion ---\")\n",
        "df_prediccion.info()"
      ],
      "id": "feature_selection_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Preprocesamiento para el Modelo"
      ],
      "metadata": {
        "id": "preprocessing_markdown"
      },
      "id": "preprocessing_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Codificación de la Variable 'Estrato'\n",
        "\n",
        "La variable `Estrato` es categórica (ej. 'Estrato 1', 'Estrato 2'). Los modelos de Machine Learning requieren entradas numéricas. Convertiremos 'Estrato' a un tipo numérico ordinal, ya que los estratos tienen un orden inherente."
      ],
      "metadata": {
        "id": "encode_estrato_markdown"
      },
      "id": "encode_estrato_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "encode_estrato_code"
      },
      "outputs": [],
      "source": [
        "if df_prediccion['Estrato'].dtype == 'object' or isinstance(df_prediccion['Estrato'].dtype, pd.CategoricalDtype):\n",
        "    print(\"Codificando 'Estrato' de tipo objeto/categórico a numérico.\")\n",
        "    try:\n",
        "        df_prediccion['Estrato'] = df_prediccion['Estrato'].str.replace('Estrato ', '', regex=False).astype(int)\n",
        "    except AttributeError:\n",
        "        # Si ya es numérico (por ejemplo, si el parquet ya lo tiene como número pero leído como category)\n",
        "        df_prediccion['Estrato'] = df_prediccion['Estrato'].astype(str).str.replace('Estrato ', '', regex=False).astype(int)\n",
        "else:\n",
        "    print(\"'Estrato' ya es numérico.\")\n",
        "    df_prediccion['Estrato'] = df_prediccion['Estrato'].astype(int) # Asegurar que es int\n",
        "\n",
        "print(\"\\n--- 'Estrato' después de la codificación ---\")\n",
        "print(df_prediccion[['Estrato']].head())\n",
        "print(df_prediccion['Estrato'].value_counts())"
      ],
      "id": "encode_estrato_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Manejo de Valores Faltantes (NaN)\n",
        "\n",
        "Verificamos si hay valores faltantes en las características seleccionadas. Para este tutorial, si hay pocos, podríamos eliminarlos o usar una imputación simple. Los modelos como RandomForest pueden manejar NaNs en algunas implementaciones, pero es buena práctica tratarlos."
      ],
      "metadata": {
        "id": "handle_nan_markdown"
      },
      "id": "handle_nan_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "handle_nan_code"
      },
      "outputs": [],
      "source": [
        "print(\"--- Valores faltantes en df_prediccion antes del manejo ---\")\n",
        "print(df_prediccion.isnull().sum())\n",
        "\n",
        "# Estrategia simple: eliminar filas con NaNs en las características o el target\n",
        "# (Considerar imputación para un caso real más complejo)\n",
        "df_prediccion_final = df_prediccion.dropna()\n",
        "\n",
        "print(f\"\\nShape original: {df_prediccion.shape}\")\n",
        "print(f\"Shape después de dropna: {df_prediccion_final.shape}\")\n",
        "print(\"\\n--- Valores faltantes en df_prediccion_final después del manejo ---\")\n",
        "print(df_prediccion_final.isnull().sum())"
      ],
      "id": "handle_nan_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Definición de X (Características) e y (Variable Objetivo)"
      ],
      "metadata": {
        "id": "define_X_y_markdown"
      },
      "id": "define_X_y_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_X_y_code"
      },
      "outputs": [],
      "source": [
        "X = df_prediccion_final.drop(target, axis=1)\n",
        "y = df_prediccion_final[target]\n",
        "\n",
        "print(\"--- Características (X) ---\")\n",
        "print(X.head())\n",
        "print(\"\\n--- Variable Objetivo (y) ---\")\n",
        "print(y.head())\n",
        "print(\"\\nDistribución de la variable objetivo 'Mora':\")\n",
        "print(y.value_counts(normalize=True))"
      ],
      "id": "define_X_y_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "La distribución de la variable objetivo `Mora` nos indica si hay un desbalance de clases. Si una clase es mucho más frecuente que la otra, podríamos necesitar técnicas especiales (como `class_weight='balanced'` en el modelo o sobremuestreo/submuestreo)."
      ],
      "metadata": {
        "id": "class_imbalance_note_markdown"
      },
      "id": "class_imbalance_note_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. División de Datos: Entrenamiento y Prueba"
      ],
      "metadata": {
        "id": "train_test_split_markdown"
      },
      "id": "train_test_split_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos los datos en un conjunto de entrenamiento (para que el modelo aprenda) y un conjunto de prueba (para evaluar su rendimiento en datos no vistos).\n",
        "Usamos `stratify=y` para asegurar que la proporción de clases en `Mora` sea similar en ambos conjuntos."
      ],
      "metadata": {
        "id": "explain_tts_markdown"
      },
      "id": "explain_tts_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_test_split_code"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Tamaño de X_train: {X_train.shape}\")\n",
        "print(f\"Tamaño de X_test: {X_test.shape}\")\n",
        "print(f\"Tamaño de y_train: {y_train.shape}\")\n",
        "print(f\"Tamaño de y_test: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nProporción de 'Mora' en y_train:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nProporción de 'Mora' en y_test:\")\n",
        "print(y_test.value_counts(normalize=True))"
      ],
      "id": "train_test_split_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Entrenamiento del Modelo (Random Forest Classifier)"
      ],
      "metadata": {
        "id": "model_training_markdown"
      },
      "id": "model_training_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos un `RandomForestClassifier`. Es un modelo de ensamble robusto y popular.\n",
        "El parámetro `class_weight='balanced'` ayuda al modelo a tratar de manera más equitativa las clases si hay desbalance."
      ],
      "metadata": {
        "id": "explain_rf_markdown"
      },
      "id": "explain_rf_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_training_code"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Modelo RandomForestClassifier entrenado.\")"
      ],
      "id": "model_training_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluación del Modelo"
      ],
      "metadata": {
        "id": "model_evaluation_markdown"
      },
      "id": "model_evaluation_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluaremos el modelo en el conjunto de prueba usando varias métricas:"
      ],
      "metadata": {
        "id": "eval_intro_markdown"
      },
      "id": "eval_intro_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_evaluation_code"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"--- Resultados de la Evaluación ---\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Visualización de la Matriz de Confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Mora (0)', 'Mora (1)'], yticklabels=['No Mora (0)', 'Mora (1)'])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "id": "model_evaluation_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de las Métricas:**\n",
        "* **Accuracy:** Proporción de predicciones correctas. Puede ser engañosa si las clases están desbalanceadas.\n",
        "* **Classification Report:**\n",
        "    * **Precision (Precisión):** De todas las predicciones para una clase, ¿cuántas fueron correctas? (TP / (TP + FP)). Importante si el costo de un Falso Positivo es alto.\n",
        "    * **Recall (Sensibilidad):** De todos los casos reales de una clase, ¿cuántos se identificaron correctamente? (TP / (TP + FN)). Importante si el costo de un Falso Negativo es alto (e.g., no detectar una factura que entrará en mora).\n",
        "    * **F1-score:** Media armónica de Precision y Recall. Buen indicador general del rendimiento, especialmente con clases desbalanceadas.\n",
        "    * **Support:** Número de instancias reales de cada clase.\n",
        "* **Confusion Matrix (Matriz de Confusión):**\n",
        "    * **Verdaderos Negativos (TN):** Casos 'No Mora' predichos correctamente como 'No Mora'.\n",
        "    * **Falsos Positivos (FP):** Casos 'No Mora' predichos incorrectamente como 'Mora' (Error Tipo I).\n",
        "    * **Falsos Negativos (FN):** Casos 'Mora' predichos incorrectamente como 'No Mora' (Error Tipo II).\n",
        "    * **Verdaderos Positivos (TP):** Casos 'Mora' predichos correctamente como 'Mora'."
      ],
      "metadata": {
        "id": "metrics_interpretation_markdown"
      },
      "id": "metrics_interpretation_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Importancia de las Características"
      ],
      "metadata": {
        "id": "feature_importance_markdown"
      },
      "id": "feature_importance_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest nos permite ver qué características fueron más influyentes en la predicción."
      ],
      "metadata": {
        "id": "explain_feat_imp_markdown"
      },
      "id": "explain_feat_imp_markdown"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_importance_code"
      },
      "outputs": [],
      "source": [
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "plt.title('Importancia de las Características para Predecir Mora')\n",
        "plt.show()\n",
        "\n",
        "print(feature_importance_df)"
      ],
      "id": "feature_importance_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de la Importancia de Características:**\n",
        "Esto nos muestra qué factores considera el modelo como los más decisivos para determinar si una factura entrará en mora. Puede guiar decisiones de negocio o refinamientos futuros del modelo."
      ],
      "metadata": {
        "id": "interpret_feat_imp_markdown"
      },
      "id": "interpret_feat_imp_markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Discusión de Resultados y Próximos Pasos\n",
        "\n",
        "**Preguntas para la discusión:**\n",
        "* ¿Es bueno el accuracy? ¿Cómo son precision/recall para la clase 'Mora=1'? ¿Qué características son las más importantes?\n",
        "* El modelo (Random Forest) es bueno, regular o malo? para predecir la mora bajo las condiciones actuales y con las características seleccionadas.\n",
        "* Es crucial recordar que se evitó el data leakage al no incluir `Dias_PagoOportuno_PagoReal`.\n",
        "\n",
        "**Limitaciones y Consideraciones:**\n",
        "* **Calidad de los datos:** El rendimiento del modelo depende de la calidad y representatividad de los datos de entrada.\n",
        "* **Ingeniería de características:** Podrían explorarse más características (e.g., historial de pago del cliente, variaciones en el consumo, etc.).\n",
        "* **Balance de clases:** Si la clase 'Mora=1' es minoritaria, el accuracy puede no ser la mejor métrica. F1-score, recall para la clase minoritaria, o AUC-ROC (no calculado aquí) son más informativos.\n",
        "* **Simplificación:** Se usó una estrategia simple de manejo de NaNs. Métodos más sofisticados podrían ser necesarios.\n",
        "\n",
        "**Próximos Pasos Potenciales:**\n",
        "* **Optimización de Hiperparámetros:** Usar técnicas como GridSearchCV o RandomizedSearchCV para encontrar la mejor combinación de hiperparámetros para el RandomForest.\n",
        "* **Probar otros modelos:** Evaluar otros algoritmos (e.g., Logistic Regression, Gradient Boosting, SVM).\n",
        "* **Ingeniería de Características Avanzada:** Crear variables más complejas o basadas en el dominio del problema.\n",
        "* **Análisis de Errores:** Investigar los casos donde el modelo se equivoca (Falsos Positivos y Falsos Negativos) para entender sus debilidades.\n",
        "* **Puesta en Producción:** Si el modelo es satisfactorio, planificar cómo se integraría en un sistema para hacer predicciones sobre nuevas facturas.\n",
        "\n",
        "Este tutorial proporciona una base para la predicción de mora. El modelado es un proceso iterativo de experimentación y mejora."
      ],
      "metadata": {
        "id": "discussion_conclusion_markdown"
      },
      "id": "discussion_conclusion_markdown"
    }
  ]
}